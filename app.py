import streamlit as st
import os
import arxiv
# [Cloud Change]: å¯¼å…¥ HuggingFaceHub ä»¥ä¾¿é€šè¿‡APIè°ƒç”¨æ¨¡å‹
from langchain_community.llms import HuggingFaceHub
from dotenv import load_dotenv
from langchain_community.document_loaders import PyMuPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate

# --- éƒ¨ç½²å‡†å¤‡: åŠ è½½ç¯å¢ƒå˜é‡ ---
# åœ¨æœ¬åœ°ï¼Œè¿™ä¼šåŠ è½½ .env æ–‡ä»¶ã€‚åœ¨Streamlit Cloudä¸Šï¼Œå®ƒä¼šè¯»å–æ‚¨è®¾ç½®çš„Secretsã€‚
load_dotenv()

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="AIè®ºæ–‡æœç´¢ä¸é—®ç­”æœºå™¨äºº", page_icon=" C", layout="wide")
st.title(" C AIè®ºæ–‡æœç´¢ä¸é—®ç­”æœºå™¨äºº")
st.write("åœ¨è¿™é‡Œï¼Œæ‚¨å¯ä»¥æœç´¢arXivä¸Šçš„è®ºæ–‡ï¼Œå¹¶ä¸é€‰å®šçš„è®ºæ–‡è¿›è¡Œæ™ºèƒ½å¯¹è¯ã€‚")

# --- 2. æ–‡ä»¶å¤¹è·¯å¾„å®šä¹‰ ---
# åœ¨äº‘ç«¯ä¸´æ—¶æ–‡ä»¶ç³»ç»Ÿä¸­ä½¿ç”¨ä¸€ä¸ªç®€å•çš„æ–‡ä»¶å¤¹åå³å¯
PDF_SAVE_PATH = "../project/downloaded_papers"
if not os.path.exists(PDF_SAVE_PATH):
    os.makedirs(PDF_SAVE_PATH)


# --- 3. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° (ç¼“å­˜ä»¥æé«˜æ€§èƒ½) ---
@st.cache_resource
def setup_pipelines(_paper_id):
    print(f"--- æ­£åœ¨ä¸ºè®ºæ–‡ {_paper_id} æ„å»ºRAGæµæ°´çº¿ ---")

    client = arxiv.Client()
    search = arxiv.Search(id_list=[_paper_id])
    paper = next(client.results(search))

    pdf_filename = f"{paper.entry_id.split('/')[-1]}.pdf"
    local_pdf_path = os.path.join(PDF_SAVE_PATH, pdf_filename)
    if not os.path.exists(local_pdf_path):
        paper.download_pdf(dirpath=PDF_SAVE_PATH, filename=pdf_filename)
    print(f"--- è®ºæ–‡PDF '{pdf_filename}' å·²å°±ç»ª ---")

    embedding_model_name = "sentence-transformers/all-MiniLM-L6-v2"
    print(f"--- æ­£åœ¨ä»HubåŠ è½½Embeddingæ¨¡å‹: {embedding_model_name} ---")
    embeddings = SentenceTransformerEmbeddings(model_name=embedding_model_name)
    print("--- Embeddingæ¨¡å‹åŠ è½½å®Œæ¯• ---")

    loader = PyMuPDFLoader(local_pdf_path)
    docs = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents(docs)

    print("--- æ­£åœ¨ä¸ºè®ºæ–‡åˆ›å»ºå‘é‡ç´¢å¼•... ---")
    vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)
    print("--- å‘é‡ç´¢å¼•åˆ›å»ºå®Œæˆï¼ ---")

    retriever = vectorstore.as_retriever(search_kwargs={'k': 6})

    # ===================================================================
    # --- START DIAGNOSTIC BLOCK ---
    # ===================================================================
    st.info("--- æ­£åœ¨æ‰§è¡ŒLLMåˆå§‹åŒ–è¯Šæ–­ ---")

    # 1. æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦è¢«åº”ç”¨æˆåŠŸè¯»å–
    api_token = os.getenv("HUGGINGFACEHUB_API_TOKEN")
    if api_token:
        st.success("âœ… è¯Šæ–­ 1/3: æˆåŠŸä»Secretsä¸­è¯»å–åˆ° HUGGINGFACEHUB_API_TOKENã€‚")
        # ä¸ºå®‰å…¨èµ·è§ï¼Œåªæ˜¾ç¤ºéƒ¨åˆ†token
        st.write(f"Token ç‰‡æ®µ: `{api_token[:5]}...{api_token[-5:]}`")
    else:
        st.error("ğŸš¨ è¯Šæ–­ 1/3: å…³é”®å¤±è´¥ï¼æœªèƒ½ä»Secretsä¸­è¯»å–åˆ° HUGGINGFACEHUB_API_TOKENï¼è¯·æ£€æŸ¥Secretsçš„åç§°æ‹¼å†™ã€‚")
        st.stop()  # å¦‚æœæ²¡æœ‰tokenï¼Œç›´æ¥åœæ­¢è¿è¡Œ

    # 2. å°è¯•åˆå§‹åŒ–HuggingFaceHubå¯¹è±¡
    repo_id = "Qwen/Qwen1.5-7B-Chat"
    llm = None  # å…ˆå£°æ˜å˜é‡
    try:
        llm = HuggingFaceHub(
            repo_id=repo_id,
            model_kwargs={"temperature": 0.3, "max_length": 2048}
        )
        st.success("âœ… è¯Šæ–­ 2/3: HuggingFaceHub å¯¹è±¡åˆå§‹åŒ–æˆåŠŸï¼")
        st.write(f"LLM å¯¹è±¡ç±»å‹: `{type(llm)}`")
    except Exception as e:
        st.error(f"ğŸš¨ è¯Šæ–­ 2/3: å…³é”®å¤±è´¥ï¼åœ¨åˆå§‹åŒ– HuggingFaceHub å¯¹è±¡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        st.stop()

    # 3. æ£€æŸ¥å†…éƒ¨å®¢æˆ·ç«¯æ˜¯å¦å­˜åœ¨ (AttributeErrorçš„ç›´æ¥åŸå› )
    if hasattr(llm, 'client') and llm.client is not None:
        st.success("âœ… è¯Šæ–­ 3/3: å†…éƒ¨ `llm.client` å¯¹è±¡å­˜åœ¨ä¸”ä¸ä¸ºç©ºã€‚")
    else:
        st.warning("âš ï¸ è¯Šæ–­ 3/3: è­¦å‘Šï¼å†…éƒ¨ `llm.client` å¯¹è±¡ç¼ºå¤±æˆ–ä¸ºç©ºï¼è¿™å¯èƒ½æ˜¯ç‰ˆæœ¬ä¸å…¼å®¹å¯¼è‡´çš„ã€‚")

    st.info("--- LLMåˆå§‹åŒ–è¯Šæ–­ç»“æŸ ---")
    # ===================================================================
    # --- END DIAGNOSTIC BLOCK ---
    # ===================================================================

    qa_template = """[ä»»åŠ¡æŒ‡ä»¤]
    ä½ æ˜¯ä¸€ä¸ªé¡¶çº§çš„AIå­¦æœ¯ç ”ç©¶å‘˜...
    """  # (æ¨¡æ¿å†…å®¹ä¿æŒä¸å˜)
    QA_PROMPT = PromptTemplate.from_template(qa_template)

    memory = ConversationBufferMemory(
        memory_key="chat_history", return_messages=True, output_key='answer'
    )

    rag_chain = ConversationalRetrievalChain.from_llm(
        llm=llm, retriever=retriever, memory=memory,
        combine_docs_chain_kwargs={"prompt": QA_PROMPT},
        return_source_documents=True
    )

    print("--- RAGæµæ°´çº¿æ„å»ºå®Œæˆ ---")
    return rag_chain

# --- Session State and App Flow (è¿™éƒ¨åˆ†ä»£ç å’Œæ‚¨æœ¬åœ°æˆåŠŸè¿è¡Œçš„ç‰ˆæœ¬å®Œå…¨ä¸€æ ·ï¼Œæ— éœ€æ”¹åŠ¨) ---
if 'stage' not in st.session_state:
    st.session_state.stage = 'search'
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'rag_chain' not in st.session_state:
    st.session_state.rag_chain = None

if st.session_state.stage == 'search':
    st.header("1. æœç´¢è®ºæ–‡")
    query = st.text_input("è¾“å…¥æ‚¨æƒ³æœç´¢çš„è®ºæ–‡å…³é”®è¯ (ä¾‹å¦‚: 'large language model')", key="search_query")
    if st.button(" C æœç´¢"):
        if query:
            with st.spinner("æ­£åœ¨arXivä¸Šæœç´¢..."):
                client = arxiv.Client()
                search = arxiv.Search(query=query, max_results=5, sort_by=arxiv.SortCriterion.Relevance)
                results = list(client.results(search))
                if results:
                    st.session_state.search_results = results
                    st.session_state.stage = 'select'
                    st.rerun()
                else:
                    st.error("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„è®ºæ–‡ï¼Œè¯·æ¢ä¸ªå…³é”®è¯è¯•è¯•ã€‚")
        else:
            st.warning("è¯·è¾“å…¥æœç´¢å…³é”®è¯ã€‚")

elif st.session_state.stage == 'select':
    st.header("2. é€‰æ‹©ä¸€ç¯‡è®ºæ–‡è¿›è¡Œå¯¹è¯")
    if 'search_results' in st.session_state and st.session_state.search_results:
        for paper in st.session_state.search_results:
            st.subheader(paper.title)
            st.write(f"**ä½œè€…**: {', '.join(author.name for author in paper.authors)}")
            st.write(f"**æ‘˜è¦**: {paper.summary[:300]}...")
            paper_id = paper.entry_id.split('/')[-1]
            if st.button(f" C ä¸è¿™ç¯‡è®ºæ–‡å¯¹è¯", key=f"select_{paper_id}"):
                st.session_state.selected_paper_id = paper_id
                st.session_state.stage = 'chat'
                st.rerun()
    if st.button("è¿”å›æœç´¢"):
        st.session_state.pop('search_results', None)
        st.session_state.stage = 'search'
        st.rerun()

elif st.session_state.stage == 'chat':
    paper_id = st.session_state.selected_paper_id

    if st.session_state.rag_chain is None:
        with st.status(f"æ­£åœ¨å‡†å¤‡ä¸è®ºæ–‡ {paper_id} çš„å¯¹è¯ç¯å¢ƒ...", expanded=True) as status:
            try:
                status.write(" C æ­£åœ¨ä¸‹è½½è®ºæ–‡PDF...")
                client = arxiv.Client()
                search = arxiv.Search(id_list=[paper_id])
                paper_metadata = next(client.results(search))
                pdf_filename = f"{paper_metadata.entry_id.split('/')[-1]}.pdf"
                downloaded_pdf_path = os.path.join(PDF_SAVE_PATH, pdf_filename)
                if not os.path.exists(downloaded_pdf_path):
                    paper_metadata.download_pdf(dirpath=PDF_SAVE_PATH, filename=pdf_filename)
                st.session_state.paper_metadata = paper_metadata
                st.session_state.downloaded_pdf_path = downloaded_pdf_path

                status.write(f" C æ­£åœ¨æ„å»ºRAGæµæ°´çº¿...")
                st.session_state.rag_chain = setup_pipelines(paper_id)

                status.update(label=" C ç¯å¢ƒå‡†å¤‡å®Œæˆï¼", state="complete", expanded=False)

            except Exception as e:
                status.update(label=f"ç¯å¢ƒå‡†å¤‡å¤±è´¥: {e}", state="error")
                st.session_state.stage = 'select'
                if st.button("è¿”å›é‡è¯•"):
                    st.rerun()

    if st.session_state.rag_chain:
        st.header(f"3. æ­£åœ¨ä¸è®ºæ–‡å¯¹è¯: {st.session_state.paper_metadata.title}")

        with open(st.session_state.downloaded_pdf_path, "rb") as pdf_file:
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½å½“å‰è®ºæ–‡PDF",
                data=pdf_file,
                file_name=os.path.basename(st.session_state.downloaded_pdf_path),
                mime="application/octet-stream"
            )

        st.divider()

        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        user_question = st.chat_input("è¯·å°±è¿™ç¯‡è®ºæ–‡æé—®ï¼š")
        if user_question:
            st.session_state.messages.append({"role": "user", "content": user_question})
            with st.chat_message("user"):
                st.markdown(user_question)

            with st.spinner("æ¨¡å‹æ­£åœ¨æ£€ç´¢ä¸æ€è€ƒä¸­..."):
                result = st.session_state.rag_chain({"question": user_question})
                ai_response = result['answer']
                st.session_state.messages.append({"role": "assistant", "content": ai_response})

                with st.chat_message("assistant"):
                    st.markdown(ai_response)
                    with st.expander("æŸ¥çœ‹æœ¬æ¬¡å›ç­”å¼•ç”¨çš„åŸæ–‡ç‰‡æ®µ"):
                        for doc in result.get('source_documents', []):
                            st.markdown(
                                f"> {doc.page_content}\n\n_(æ¥æº: PDF ç¬¬ {doc.metadata.get('page', 'N/A')} é¡µ)_")

    if st.button(" C è¿”å›è®ºæ–‡é€‰æ‹©åˆ—è¡¨"):
        st.session_state.stage = 'select'
        st.session_state.messages = []
        st.session_state.rag_chain = None
        st.session_state.pop('selected_paper_id', None)
        st.session_state.pop('paper_metadata', None)
        st.session_state.pop('downloaded_pdf_path', None)
        st.rerun()
